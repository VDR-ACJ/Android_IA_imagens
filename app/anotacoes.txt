site para treinar modelos
https://teachablemachine.withgoogle.com/train/image

Analisando as imagens da pasta
Na pasta selecionada, temos algumas imagens, como uma caneca da Alura. Ao analisar essa imagem, o aplicativo traz alguns rótulos em inglês, como "tableware, cup" (utensílio de mesa, xícara), sugerindo que é uma xícara de porcelana. No entanto, ao acessar a opção de IA, vemos que identifica um grupo de comidas, mas não há nada relacionado à nossa xícara.

Isso ocorre porque o modelo atualmente disponível não tem informações para reconhecer especificamente essa xícara. Essa situação é comum ao trabalhar com bibliotecas de reconhecimento de imagem, onde muitas vezes é necessário treinar o modelo para reconhecer objetos específicos ou criar modelos personalizados para atender a necessidades específicas.

Treinamento de modelos
Na documentação do ML Kit, há uma seção de informações sobre modelos personalizados. São mencionadas algumas opções para baixar modelos pré-treinados, como para identificar carros ou certos tipos de animais. A documentação oferece várias opções que você pode explorar, incluindo modelos disponíveis para download e instalação, bem como a possibilidade de criar seus próprios modelos personalizados.

Aprendendo a utilizar o Teachable Machine
Além disso, existe a opção de treinar seus próprios modelos para uso com o ML Kit. Para isso, podemos acessar o site https://teachablemachine.withgoogle.com/, que é parte da rede da Google. Ele oferece uma maneira mais simples para quem não quer se aprofundar tanto no treinamento de modelos, permitindo treinar rapidamente e testar os modelos em seus aplicativos.

É importante ressaltar que o campo de treinamento de modelos é bastante complexo e há cursos e formações disponíveis na Alura que tratam desses aspectos de forma mais aprofundada, incluindo como preparar os dados antes de alimentar os modelos. A abordagem da Google com o Teachable Machine é fornecer uma introdução mais simples e direta para que os usuários possam começar a entender o processo, e aprofundar conforme necessário dependendo da situação.

Ao clicarmos no botão "Get Started", destacado em azul, seremos direcionados para uma tela com três opções para treinar imagens, áudios e poses. Optaremos pela seleção de "Image Project" e escolheremos o "Standard Image Model". Embora haja um breve tutorial sobre o uso do site, clicaremos no botão "X" para fechar essa apresentação. O próximo passo é definir categorias, que funcionarão como rótulos, e associar imagens de referência para estes rótulos.

Por exemplo, vamos renomear o primeiro rótulo, atualmente denominado "Class 1", para "Android". Depois, clicaremos no botão "Upload". Vale ressaltar que há um conteúdo adicional disponível na Alura sobre Teachable Machine, explicando seu uso, incluindo a funcionalidade da webcam. No entanto, nosso foco será no processo de upload de imagens.

Após clicarmos em "Upload", selecionaremos "Choose Images from your Files" para termos acesso às pastas armazenadas em nosso computador. Já organizamos as imagens necessárias na pasta "exemplo 2", dentro de "imagens de exemplo", conforme indicado nos materiais extras. Dentro dessa pasta, encontramos uma coleção de imagens do boneco do Android na pasta "android". Selecionaremos todas as imagens desta pasta e clicaremos em "Abrir". O sistema realizará o carregamento das imagens, permitindo que continuemos com a definição de outra categoria.

Para a segunda classe, renomearemos "Class 2" como "Maça", por exemplo. Repetiremos o processo de upload, selecionando as imagens correspondentes à pasta "maça", também dentro de "exemplo 2". Selecionaremos todas as imagens e clicaremos em "Abrir". Depois, basta aguardar enquanto as imagens são carregadas. É possível que surja um breve tutorial sobre o treinamento do modelo, o qual é bastante intuitivo.

Após o envio de várias imagens para as categorias "Android" e "Maça", podemos iniciar o processo de treinamento clicando em "Train Model" e aguardar sua conclusão. Quanto maior o número de imagens, melhor será o resultado do modelo e mais tempo será necessário para o treinamento. Neste caso, o processo foi relativamente rápido. Ao finalizar, o sistema oferece a opção de exportar o modelo, mas não faremos isso agora.

Testando o modelo
Uma funcionalidade interessante é a possibilidade de trocar o método de entrada de "Webcam" para "File". Assim como no exemplo anterior, podemos arrastar uma imagem para o campo designado e o sistema tentará identificar se ela pertence à categoria "Android" ou "Maça".

Então, vamos alterar para "File" e selecionar uma imagem de teste da pasta "Imagens de Exemplo". Nesta pasta, além de outras subpastas, temos algumas imagens, dentre elas a imagem "teste-android.jpg". Vamos selecioná-la e clicar em "Abrir".

Embora esta imagem especificamente não tenha sido previamente incluída no modelo, com base no treinamento anterior, o sistema atribuirá uma alta probabilidade de 100% à categoria "Android". Da mesma forma, ao testarmos a imagem "teste-caneca-e-maca.jpg", de uma maçã com uma xícara, a certeza de pertencer à categoria "Maça" é de 98%.

Adicionando mais classes
Vamos adicionar mais duas categorias, clicando em "Add a class". A primeira será "Caneca Comum" e nela selecionaremos todas as imagens da pasta "caneca comum", dentro de "exemplo 2".

Depois, criaremos a classe "Caneca Alura" e selecionaremos as imagens da pasta "caneca preta". Após o envio das imagens, iniciaremos novamente o treinamento do modelo e aguardaremos sua conclusão.

Testando novamente o modelo
Após o treinamento do nosso modelo, podemos realizar mais um teste. Vamos alterar de "Webcam" para "File" e escolher a imagem "teste-caneca-alura-1.jpg". Ao analisar a imagem, o modelo atribui uma probabilidade de 84% para a categoria "Caneca Comum" em vez de "Caneca Alura". Isso ocorre devido à semelhança das imagens utilizadas no treinamento, as quais se assemelham mais à "Caneca Comum". No entanto, é importante notar que a cor da caneca Alura pode variar, tornando-a mais parecida com outros exemplos utilizados no treinamento.

Apesar disso, nosso modelo está bem treinado e atende aos nossos requisitos. Existem opções avançadas disponíveis, como a possibilidade de retreinamento do modelo, adição ou remoção de imagens para aprimorar ainda mais seu desempenho. Quanto mais imagens semelhantes forem adicionadas, melhor será o resultado dos testes realizados.

Exportando o modelo
Ao clicarmos em "Export Model" e selecionarmos "TensorFlow Lite" com a opção Model Conversion Type configurada para "Quantized", o modelo será convertido e estará disponível para download. Este arquivo poderá ser utilizado posteriormente com o ML Kit, conforme exploraremos a seguir.

Após o término da conversão, o modelo será baixado automaticamente. Vamos aprender como incorporar este arquivo em nosso aplicativo nas próximas etapas. Para mais informações sobre como utilizar este modelo, existem instruções detalhadas nesta página, embora nosso método de utilização possa diferir um pouco. Na sequência, entenderemos essas diferenças e aprenderemos como utilizar.




Para criar os modelos customizados você precisa:

Abrir o site Teachable Machine:
Escolha a opção de imagens;
Crie as 4 classes para cada categoria;
Adicione imagens para cada categoria;
Treine o modelo;
Faça o download no formato específico.


O Teachable Machine é um projeto da Google que visa facilitar ao máximo a criação e implantação de modelos de Machine Learning. Em aula, mencionamos algumas de suas funções, mas há outras que não foram abordadas. Ainda assim, é uma ferramenta mais simples e intuitiva de usar.

Porém, existe todo uma área dentro do estudo de Machine Learning que envolve classificação e treinamento de modelos com ferramentas e códigos mais específicos. Isso inclui questões de refinamento para tornar os modelos mais precisos e eficazes.

Aqui na Alura, temos uma formação de entrada sobre esses tópicos chamada Formação Machine Learning com Python: Classificação, e também uma formação mais avançada chamada Formação Machine Learning. E se você quiser aprender mais sobre o Teachable Machine, pode conferir também o Alura Mais Visão Computacional.

========================================================

Instalação da biblioteca
Essa documentação é semelhante à que vimos para a biblioteca com o modelo comum, mas contém códigos específicos para modelos customizados. Vamos procurar a seção "Antes de Começar", que descreve como instalar essa biblioteca, cujo processo é semelhante ao que já fizemos anteriormente. Vamos copiar a linha implementation 'com.google.mlkit:image-labeling-custom:17.0.2'.

Agora, abriremos nosso projeto no Android Studio e localizaremos o arquivo build.gradle.kts do módulo app. Na linha 87, abaixo da implementação existente, colaremos a linha copiada, substituindo as aspas simples por aspas duplas e envolvendo o trecho entre parênteses.

implementation ("com.google.mlkit:image-labeling-custom:17.0.2")
Copiar código
Em seguida, pressionaremos "Alt + Enter" e selecionaremos a opção "Replace with new library catalog...". Feito isso, sincronizamos o projeto clicando em "Sync Now", na barra superior que surgiu, e aguardamos a conclusão do processo de sincronização.

Extraindo e inserindo os arquivos do modelo
Nosso projeto já fez o download da dependência, agora precisamos inserir esse modelo no nosso projeto para utilizá-lo no código. Vamos começar extraindo os arquivos do arquivo zip que baixamos do Teachable Machine. Ao clicar com o botão direito do mouse no arquivo no gerenciador de arquivos, selecionaremos a opção "Extrair Tudo". Isso nos fornecerá os arquivos labels.txt e model.tflite.

Vamos copiar esses dois arquivos e colá-los no diretório raiz do nosso projeto no Android Studio. Para isso, selecionamos o diretório no menu lateral do Android Studio, clicamos com o botão direito do mouse e vamos em "New" > "Folder" > "Assets Folder" para criar uma nova pasta chamada "assets". Em seguida, essa pasta aparecerá no menu lateral, então basta selecioná-la e usar o atalho "Ctrl + V" para colar os arquivos. Ao fazer isso, um dos arquivos é automaticamente aberto.

Note que no arquivo labels.txt temos os rótulos que criamos no Teachable Machine:

0 Android
1 Maça
2 Caneca Comum
3 Caneca Alura
Copiar código
Ao clicar no arquivo model.tflite, que se trata do modelo em si, não temos nenhuma informação relevante.

Configurando o ImageClassifier:
Com os arquivos dentro do projeto, podemos fazer algumas alterações no código de ImageClassifier.kt. Primeiramente, vamos substituir o uso do labeler padrão pelo nosso novo modelo. No método classifyImage, na linha 26, criaremos uma variável customModel, que receberá uma instância de LocalModel.Builder(). Neste momento, é importante teclar "Alt + Enter" sobre LocalModel e importá-lo.

val customModel = LocalModel.Builder()
Copiar código
Na linha seguinte, passaremos .setAssetFilePath(), com o caminho do nosso modelo. Uma vez que armazenamos o modelo em uma pasta específica para recursos do projeto, a assets, podemos simplesmente passar seu nome dentro da string: "model.tflite". Como estamos lidando com um Builder, podemos finalizar com .build().

val customModel = LocalModel.Builder()
    .setAssetFilePath("model.tflite")
    .build()
Copiar código
Agora, precisamos passar esse modelo com algumas opções para realizar a análise. Então, vamos criar uma variável chamada customOptions, que será do tipo CustomImageLabelerOptions. Ela também é um builder, então vamos adicionar .Builder() e passar customModel.

val customOptions = CustomImageLabelerOptions.Builder(customModel)
Copiar código
Na linha seguinte, vamos adicionar o parâmetro de confiança .setConfidenceThreshold(). Por padrão, ele sugere 0.7, mas, por enquanto, vamos definir como 0.2f. Lembre-se que o f é usado para indicar que é um valor float.

Temos a opção de adicionar mais um parâmetro que é a quantidade máxima de rótulos que o modelo vai retornar, mas para esse primeiro teste não faremos isso. Vamos apenas adicionar .build() para finalizar a construção das opções.

val customOptions = CustomImageLabelerOptions.Builder(customModel)
    .setConfidenceThreshold(0.2f)
    .build()
Copiar código
Agora que as customOptions estão prontas, podemos substituir as opções padrão, que estão no método .getClient(), por customOptions.

val labeler = ImageLabeling.getClient(customOptions)
Copiar código
Executando e analisando o resultado
Se rodarmos o nosso aplicativo, vamos notar pelo menos uma diferença, então vamos pressionar "Shift + F10".

Nosso aplicativo rodou e aqui há um detalhe: como adicionamos uma nova biblioteca, o projeto agora tem alguns arquivos adicionais para ler. Esse primeiro build, após as adições, pode demorar um pouco mais, mas depois ele voltará à mesma velocidade de antes.

Agora vamos verificar se ele conseguiu identificar as imagens com base no nosso modelo personalizado. Ao clicar na maçã, não está mostrando nada. Ao clicar na foto do Android, que testamos e vimos que funcionou no Teachable Machine, também não veremos nada.

No entanto, ao voltarmos ao Android Studio e observarmos o Logcat, podemos notar que, pelo menos lá, essas informações estão aparecendo:

0.99689375

0.99609375

0.97265625

0.859375

Embora não mostre corretamente o rótulo, pois está exibindo um espaço em branco, ele é capaz de fornecer algumas porcentagens, como 99%, 97% e 85%. Isso indica que o modelo está funcionando, mas ainda não consegue nos fornecer o nome de cada rótulo. Existem algumas maneiras de resolvermos esse problema, e é isso que vamos explorar a seguir.

=====================================